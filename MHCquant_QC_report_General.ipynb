{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Imports and Setups"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Import necessary libraries\n","import os\n","import csv\n","import re\n","import logging\n","import multiqc\n","import numpy as np\n","from collections import Counter, OrderedDict\n","from multiqc import BaseMultiqcModule\n","from multiqc.plots import linegraph, bargraph, table, scatter\n","from IPython.display import IFrame, display\n","\n","# Define paths for the input and output\n","tsv_folder_path = \"/home/evasam/multiqc_skript/TSV_Dateien\"\n","report_path = \"/home/evasam/multiqc_skript/my_multiqc_report\"\n","plots_path = os.path.join(report_path, 'plots')\n","os.makedirs(plots_path, exist_ok=True)\n","\n","# Configure logging\n","log = logging.getLogger('multiqc')\n","log.setLevel(logging.DEBUG) \n","\n","if not log.handlers:\n","    handler = logging.StreamHandler()\n","    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n","    handler.setFormatter(formatter)\n","    log.addHandler(handler)"]},{"cell_type":"markdown","metadata":{},"source":["# Remove existing MultiQC modules"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Function to remove any existing modules with the same name\n","def remove_existing_module(module_name):\n","    existing_modules = [m for m in multiqc.report.modules if m.name == module_name]\n","    for m in existing_modules:\n","        multiqc.report.modules.remove(m)\n","\n","# Remove old module before adding the new one\n","remove_existing_module(\"General Statistics MHCquant\")"]},{"cell_type":"markdown","metadata":{},"source":["# Initialize MultiQC Module"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Initialize and configure the MultiQC module with a custom name\n","module = BaseMultiqcModule(name=\"General Statistics MHCquant\", anchor=\"custom_data\")"]},{"cell_type":"markdown","metadata":{},"source":["# Load and Process Sequences for Peptide Length Distribution"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Function to load sequences from TSV files\n","def load_sequences(folder_path):\n","    sequence_dict = {}\n","    for file_name in os.listdir(folder_path):\n","        if file_name.endswith(\".tsv\"):\n","            file_path = os.path.join(folder_path, file_name)\n","            with open(file_path, 'r') as f:\n","                reader = csv.reader(f, delimiter='\\t')\n","                headers = next(reader)\n","                rows = list(reader)\n","                if 'sequence' not in headers:\n","                    continue  # Skip files without 'sequence' column\n","                seq_index = headers.index('sequence')\n","                sequences = [re.sub(r'\\(.*?\\)', '', row[seq_index]) for row in rows]\n","                sequence_dict[file_name] = sequences\n","    return sequence_dict\n","\n","# Load and process data for peptide length distribution\n","sample_sequence_dict = load_sequences(tsv_folder_path)\n","data = {\n","    sample: dict(Counter(list(map(len, seqs)))) for sample, seqs in sample_sequence_dict.items()\n","}\n","\n","# Normalize data and multiply frequency values by 100 for percentage representation\n","data = {\n","    sample: {length: (count / sum(seq_len_count.values())) * 100 for length, count in seq_len_count.items()}\n","    for sample, seq_len_count in data.items()\n","}\n","\n","# Configuration for peptide length distribution plot\n","pconfig = {\n","    'id': 'peptide_length_distribution',\n","    'title': 'Peptide Length Distribution',\n","    'xlab': 'Peptide Length',\n","    'ylab': 'Frequency [%]',  # y-axis label reflects percentage values\n","}\n","\n","\n","# Add section with the modified data for plotting\n","module.add_section(\n","    plot=linegraph.plot(data, pconfig=pconfig),\n","    name=\"Peptide length distribution\",\n","    anchor=\"my_metrics_section\",\n",")\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Load and Process m/z Values for Distribution Plot"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Function to load m/z values from TSV files\n","def load_mz_values(folder_path):\n","    mz_dict = {}\n","    for file_name in os.listdir(folder_path):\n","        if file_name.endswith(\".tsv\"):\n","            file_path = os.path.join(folder_path, file_name)\n","            with open(file_path, 'r') as f:\n","                reader = csv.reader(f, delimiter='\\t')\n","                headers = next(reader)\n","                rows = list(reader)\n","                if 'mz' not in headers:\n","                    log.warning(f\"WARNING: 'mz' column not found in {file_name}\")\n","                    continue  # Skip files without 'mz' column\n","                mz_index = headers.index('mz')\n","                mz_values = [float(row[mz_index]) for row in rows if row[mz_index]]\n","                mz_dict[file_name] = mz_values\n","    return mz_dict\n","\n","# Load and bin m/z values for bar plot\n","sample_mz_dict = load_mz_values(tsv_folder_path)\n","\n","def bin_mz_values(mz_values, bin_size=5):\n","    min_mz = int(min(mz_values))\n","    max_mz = int(max(mz_values))\n","    bins = list(range(min_mz, max_mz + bin_size, bin_size))\n","    bin_counts = {f\"{b}-{b + bin_size}\": 0 for b in bins[:-1]}\n","    for mz in mz_values:\n","        for b in bins[:-1]:\n","            if b <= mz < b + bin_size:\n","                bin_counts[f\"{b}-{b + bin_size}\"] += 1\n","                break\n","    return bin_counts\n","\n","mz_bin_counts = {sample: bin_mz_values(mz_values) for sample, mz_values in sample_mz_dict.items()}\n","barplot_data = OrderedDict()\n","for sample, bin_counts in mz_bin_counts.items():\n","    for bin_range, count in bin_counts.items():\n","        if bin_range not in barplot_data:\n","            barplot_data[bin_range] = {}\n","        barplot_data[bin_range][sample] = count\n","\n","# Configuration for m/z distribution bar plot\n","mz_pconfig = {\n","    'id': 'mz_distribution',\n","    'title': 'm/z Distribution',\n","    'xlab': 'm/z',\n","    'ylab': 'Frequency',\n","    'stacked': False,\n","}\n","module.add_section(\n","    plot=bargraph.plot(barplot_data, pconfig=mz_pconfig),\n","    name=\"Combined m/z Distribution\",\n","    anchor=\"mz_distribution_combined_section\",\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Calculate and Display General Statistics"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Function to calculate statistics for General Stats Table\n","def calculate_stats(folder_path):\n","    num_peptides = {}\n","    num_modified_peptides = {}\n","    num_proteins = {}\n","    for file_name in os.listdir(folder_path):\n","        if file_name.endswith(\".tsv\"):\n","            file_path = os.path.join(folder_path, file_name)\n","            with open(file_path, 'r') as f:\n","                reader = csv.DictReader(f, delimiter='\\t')\n","                sequences = set()\n","                modified_peptides = set()\n","                proteins = set()\n","                for row in reader:\n","                    sequence = row.get('sequence', '')\n","                    if sequence:\n","                        sequences.add(sequence)\n","                        if '(' in sequence and ')' in sequence:\n","                            modified_peptides.add(sequence)\n","                    for col in ['accessions', 'protein_references']:\n","                        if col in row and row[col]:\n","                            proteins.update(row[col].split(','))\n","                num_peptides[file_name] = len(sequences)\n","                num_modified_peptides[file_name] = len(modified_peptides)\n","                num_proteins[file_name] = len(proteins)\n","    return num_peptides, num_modified_peptides, num_proteins\n","\n","# Perform calculations for General Stats Table\n","num_peptides, num_modified_peptides, num_proteins = calculate_stats(tsv_folder_path)\n","general_stats_data = {\n","    file_name: {\n","        'Number of Peptides': num_peptides[file_name],\n","        'Number of Modified Peptides': num_modified_peptides[file_name],\n","        'Number of Protein Groups': num_proteins[file_name]\n","    }\n","    for file_name in num_peptides.keys()\n","}\n","headers = {\n","    'Number of Peptides': {'title': 'Number of Peptides', 'description': 'Total number of peptides'},\n","    'Number of Modified Peptides': {'title': 'Number of Modified Peptides', 'description': 'Peptides with modifications'},\n","    'Number of Protein Groups': {'title': 'Number of Protein Groups', 'description': 'Total number of protein groups'}\n","}\n","table_config = {\n","    'id': 'custom_general_stats',\n","    'title': 'Custom Statistics Table',\n","    'namespace': 'custom_data'\n","}\n","plot = table.plot(data=general_stats_data, headers=headers, pconfig=table_config)\n","module.add_section(\n","    plot=plot,\n","    name=\"Custom General Statistics\",\n","    anchor=\"custom_general_stats\"\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Load and Plot Score Data"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Function to load scores from TSV files\n","def load_score(folder_path):\n","    score_dict = {}\n","    for file_name in os.listdir(folder_path):\n","        if file_name.endswith(\".tsv\"):\n","            file_path = os.path.join(folder_path, file_name)\n","            with open(file_path, 'r') as f:\n","                reader = csv.reader(f, delimiter='\\t')\n","                headers = next(reader)\n","                rows = list(reader)\n","                if 'score' not in headers:\n","                    log.warning(f\"WARNING: 'score' column not found in {file_name}\")\n","                    continue\n","                score_index = headers.index('score')\n","                score_values = [float(row[score_index]) for row in rows if row[score_index]]\n","                score_dict[file_name] = score_values\n","    return score_dict\n","\n","# Load score data\n","sample_score_dict = load_score(tsv_folder_path)\n","\n","# Function to compute the optimal number of bins using Freedman-Diaconis rule\n","def optimal_bins(data):\n","    q25, q75 = np.percentile(data, [25, 75])  # First and third quartiles\n","    bin_width = 2 * (q75 - q25) / len(data) ** (1/3)  # Freedman-Diaconis formula\n","    bins = int((max(data) - min(data)) / bin_width)\n","    return bins\n","\n","# Create bin counts for each sample's scores using optimal number of bins\n","def bin_score_values_optimal(score_values, bin_size):\n","    bins = np.linspace(min(score_values), max(score_values), bin_size + 1)\n","    bin_counts = OrderedDict((f\"{round(bins[i], 5)}-{round(bins[i+1], 5)}\", 0) for i in range(len(bins) - 1))\n","    for score in score_values:\n","        for i in range(len(bins) - 1):\n","            if bins[i] <= score < bins[i + 1]:\n","                bin_counts[f\"{round(bins[i], 5)}-{round(bins[i + 1], 5)}\"] += 1\n","                break\n","    return bin_counts\n","\n","# Calculate optimal bins and create bin counts for each sample\n","score_bin_counts = {}\n","for sample, score_values in sample_score_dict.items():\n","    bin_size = optimal_bins(score_values)  # Calculate the optimal number of bins\n","    bin_counts = bin_score_values_optimal(score_values, bin_size)\n","    score_bin_counts[sample] = bin_counts\n","\n","# Prepare data for the bar plot\n","score_barplot_data = OrderedDict()\n","for bin_range in score_bin_counts[next(iter(score_bin_counts))].keys():  # Use the bins from the first sample as reference\n","    score_barplot_data[bin_range] = {sample: score_bin_counts[sample].get(bin_range, 0) for sample in score_bin_counts}\n","\n","# Configuration for the score distribution bar plot\n","score_pconfig = {\n","    'id': 'score_distribution_combined',\n","    'title': 'Score Distribution for All Samples',\n","    'xlab': 'Score Range',\n","    'ylab': 'Frequency',\n","    'stacked': True , # Set to True to display stacked bar plot with different colors for each file\n","}\n","\n","# Add the score distribution bar plot section\n","if score_barplot_data:  # Ensure there is data to plot\n","    module.add_section(\n","        plot=bargraph.plot(score_barplot_data, pconfig=score_pconfig),\n","        name=\"Combined Score Distribution of all Samples\",\n","        anchor=\"score_distribution_combined_section\",\n","    )\n","else:\n","    print(\"No data available for score distribution plot.\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Load and Plot Retention Time Data"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Function to load predicted and observed retention times from TSV files\n","#def load_rt_and_predicted_rt(folder_path):\n","#    scatter_data = {}\n","#    for file_name in os.listdir(folder_path):\n","#        if file_name.endswith(\".tsv\"):\n","#            file_path = os.path.join(folder_path, file_name)\n","#            with open(file_path, 'r') as f:\n","#                reader = csv.reader(f, delimiter='\\t')\n","#                headers = next(reader)\n","#                rows = list(reader)\n","#                # Check if required columns exist\n","#                if 'predicted_retention_time_best' not in headers or 'observed_retention_time_best' not in headers:\n","#                    log.warning(f\"WARNING: 'predicted_retention_time_best' or 'observed_retention_time_best' column not found in {file_name}\")\n","#                    continue\n","#                # Get indices of the required columns\n","#                predicted_rt_index = headers.index('predicted_retention_time_best')\n","#                observed_rt_index = headers.index('observed_retention_time_best')\n","#                points = []\n","#                for row in rows:\n","#                    try:\n","#                        predicted_rt_value = float(row[predicted_rt_index])\n","#                        observed_rt_value = float(row[observed_rt_index])\n","#                        points.append({\"x\": observed_rt_value, \"y\": predicted_rt_value})\n","#                    except ValueError:\n","#                        continue\n","#                if points:\n","#                    scatter_data[file_name] = points\n","#\n","#    print(f\"Scatter plot data: {scatter_data}\")  # Debugging: Print scatter plot data\n","#    return scatter_data\n","#\n","# Load the updated retention time data\n","#scatter_plot_data = load_rt_and_predicted_rt(tsv_folder_path)\n","\n","# Create a scatter plot for each file separately\n","#if scatter_plot_data:\n","#    for file_name, data_points in scatter_plot_data.items():\n","#        scatter_pconfig = {\n","#            'id': f'scatter_{file_name}',\n","#            'title': f'Scatter Plot: Predicted vs Observed Retention Time ({file_name})',\n","#            'xlab': 'Observed Retention Time (RT)',\n","#            'ylab': 'Predicted Retention Time',\n","#            'showlegend': True  # Show legend for each plot\n","#        }\n","#\n","#        # Create the scatter plot for the current file\n","#        module.add_section(\n","#            plot=scatter.plot({file_name: data_points}, pconfig=scatter_pconfig),  # Provide data for the current file\n","#            name=f\"Predicted vs Observed Retention Time Correlation ({file_name})\",\n","#            anchor=f\"rt_vs_predicted_rt_correlation_section_{file_name}\",\n","#       )\n","#else:\n","#    print(\"No data available for scatter plots.\")"]},{"cell_type":"markdown","metadata":{},"source":["# Load and Plot Peptide Counts over RT"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Function to load data and calculate peptide counts over retention time\n","def load_peptide_counts_by_rt(folder_path):\n","    rt_data = {}\n","    for file_name in os.listdir(folder_path):\n","        if file_name.endswith(\".tsv\"):\n","            file_path = os.path.join(folder_path, file_name)\n","            with open(file_path, 'r') as f:\n","                reader = csv.reader(f, delimiter='\\t')\n","                headers = next(reader)\n","                rows = list(reader)\n","                if 'observed_retention_time_best' not in headers:\n","                    log.warning(f\"WARNING: 'observed_retention_time_best' column not found in {file_name}\")\n","                    continue\n","                rt_index = headers.index('observed_retention_time_best')\n","                rt_values = [float(row[rt_index]) for row in rows if row[rt_index]]\n","                \n","                # Define bins for retention time\n","                rt_bins = [round(min(rt_values) + i * 2, 2) for i in range(int((max(rt_values) - min(rt_values)) / 2) + 1)]\n","                rt_counts = OrderedDict((bin_start, 0) for bin_start in rt_bins)\n","\n","                # Count the number of peptides in each bin\n","                for rt in rt_values:\n","                    for bin_start in rt_bins:\n","                        if bin_start <= rt < bin_start + 2:\n","                            rt_counts[bin_start] += 1\n","                            break\n","\n","                # Convert data into the required format\n","                rt_data[file_name] = {bin_start: count for bin_start, count in rt_counts.items()}\n","\n","    return rt_data\n","\n","# Load the peptide counts data\n","rt_plot_data = load_peptide_counts_by_rt(tsv_folder_path)\n","\n","# Generate line plots for each dataset\n","if rt_plot_data:\n","    line_pconfig = {\n","        'id': 'peptides_over_rt',\n","        'title': 'Number of Peptides over Retention Time',\n","        'xlab': 'Retention Time (minutes)',\n","        'ylab': 'Number of Peptides',\n","        'cpswitch': True,  # Enables clickable plot options\n","        'cpswitch_c_active': False,  # Keeps the plots in separate tabs\n","        'cpswitch_counts_label': 'Peptides Count by Retention Time',\n","        'cpswitch_percent_label': 'Peptides Percentage by Retention Time',\n","    }\n","\n","    # Create the line plot\n","    module.add_section(\n","        plot=linegraph.plot(rt_plot_data, pconfig=line_pconfig),\n","        name=\"Peptides over Retention Time\",\n","        anchor=\"peptides_over_rt_section\",\n","    )\n","else:\n","    print(\"No data available for peptide counts over retention time.\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Load and Plot Xcorr Distribution"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Function to load Xcorr data from TSV files\n","def load_xcorr(folder_path):\n","    xcorr_dict = {}\n","    for file_name in os.listdir(folder_path):\n","        if file_name.endswith(\".tsv\"):\n","            file_path = os.path.join(folder_path, file_name)\n","            with open(file_path, 'r') as f:\n","                reader = csv.reader(f, delimiter='\\t')\n","                headers = next(reader)\n","                rows = list(reader)\n","                if 'COMET:xcorr' not in headers:\n","                    log.warning(f\"WARNING: 'COMET:xcorr' column not found in {file_name}\")\n","                    continue\n","                xcorr_index = headers.index('COMET:xcorr')\n","                xcorr_values = [float(row[xcorr_index]) for row in rows if row[xcorr_index]]\n","                xcorr_dict[file_name] = xcorr_values\n","    return xcorr_dict\n","\n","# Load Xcorr data\n","sample_xcorr_dict = load_xcorr(tsv_folder_path)\n","\n","# Function to determine a common range and create bins\n","def create_common_bins(xcorr_dict, bin_size=0.1):\n","    # Find the overall min and max values across all datasets\n","    all_xcorr_values = [val for sublist in xcorr_dict.values() for val in sublist]\n","    min_xcorr = min(all_xcorr_values)\n","    max_xcorr = max(all_xcorr_values)\n","\n","    # Define common bins across all datasets\n","    bins = [min_xcorr + i * bin_size for i in range(int((max_xcorr - min_xcorr) / bin_size) + 1)]\n","    return bins\n","\n","# Function to bin Xcorr values for plotting and calculate frequencies\n","def bin_xcorr_values(xcorr_values, bins):\n","    if not xcorr_values:\n","        print(\"No Xcorr values to bin.\")\n","        return {}\n","    \n","    # Initialize bin counts\n","    bin_counts = OrderedDict((f\"{round(b, 2)}-{round(b + (bins[1] - bins[0]), 2)}\", 0) for b in bins[:-1])\n","    \n","    # Count frequencies in bins\n","    for xcorr in xcorr_values:\n","        for i, b in enumerate(bins[:-1]):\n","            if b <= xcorr < bins[i + 1]:  # Ensures no overlap and proper bin assignment\n","                bin_counts[f\"{round(b, 2)}-{round(b + (bins[1] - bins[0]), 2)}\"] += 1\n","                break\n","\n","    # Convert counts to frequencies\n","    total_count = sum(bin_counts.values())\n","    bin_frequencies = {k: (v / total_count) * 100 for k, v in bin_counts.items()}  # Convert to percentage\n","    return bin_frequencies\n","\n","# Create common bins across all datasets\n","common_bins = create_common_bins(sample_xcorr_dict)\n","\n","# Create frequency data for each sample's Xcorr values\n","xcorr_bin_frequencies = {sample: bin_xcorr_values(xcorr_values, common_bins) for sample, xcorr_values in sample_xcorr_dict.items()}\n","\n","# Prepare data for the bar plot and ensure it's sorted by numeric range\n","xcorr_barplot_data = OrderedDict()\n","for sample, bin_frequencies in xcorr_bin_frequencies.items():\n","    for bin_range, frequency in bin_frequencies.items():\n","        if bin_range not in xcorr_barplot_data:\n","            xcorr_barplot_data[bin_range] = {}\n","        xcorr_barplot_data[bin_range][sample] = frequency\n","\n","# Sort xcorr_barplot_data by the numeric start of each bin range\n","xcorr_barplot_data = OrderedDict(sorted(xcorr_barplot_data.items(), key=lambda x: float(x[0].split('-')[0])))\n","\n","# Configuration for the Xcorr distribution bar plot\n","xcorr_pconfig = {\n","    'id': 'xcorr_distribution',\n","    'title': 'Xcorr Distribution (Frequency) for All Samples',\n","    'xlab': 'Xcorr Range',\n","    'ylab': 'Frequency [%]',\n","    'xmax': max(float(bin_range.split('-')[1]) for bin_range in xcorr_barplot_data),  # Dynamically set xmax\n","    'xmin': min(float(bin_range.split('-')[0]) for bin_range in xcorr_barplot_data),  # Dynamically set xmin\n","    'stacked': False\n","}\n","\n","# Add the Xcorr distribution bar plot section\n","if xcorr_barplot_data:  # Ensure there is data to plot\n","    module.add_section(\n","        plot=bargraph.plot(xcorr_barplot_data, pconfig=xcorr_pconfig),\n","        name=\"Xcorr Distribution (Frequency)\",\n","        anchor=\"xcorr_distribution_section\",\n","    )\n","else:\n","    print(\"No data available for Xcorr distribution plot.\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Generate and Display the MultiQC Report"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m            config\u001b[0m | Loading config settings from: multiqc_config.yaml\n","\u001b[34m     update_config\u001b[0m | Report title: MHCquant QC Report\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[38;5;208m///\u001b[0m \u001b[1mhttps://multiqc.info\u001b[0m 🔍 \u001b[2mv1.23\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m     version_check\u001b[0m | \u001b[33mMultiQC Version v1.24.1 now available!\u001b[0m\n","\u001b[34m     write_results\u001b[0m | Data        : my_multiqc_report/mhcquant_multiqc_report_data   (overwritten)\n","\u001b[34m     write_results\u001b[0m | Report      : my_multiqc_report/mhcquant_multiqc_report.html   (overwritten)\n"]},{"data":{"text/html":["\n","        <iframe\n","            width=\"100%\"\n","            height=\"1000\"\n","            src=\"/home/evasam/multiqc_skript/my_multiqc_report/mhcquant_multiqc_report.html\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","            \n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.IFrame at 0x7f6804c1e580>"]},"metadata":{},"output_type":"display_data"}],"source":["# Ensure the custom data module is included in the report\n","multiqc.config.module_order = ['custom_data']\n","multiqc.config.report_title = \"MHCquant QC Report\"\n","\n","# Add the module to the MultiQC report only once\n","multiqc.report.modules.append(module)\n","\n","# Write the updated MultiQC report\n","multiqc.write_report(\n","    force=True,\n","    title=\"MHCquant QC Report\",\n","    filename=os.path.join(report_path, 'mhcquant_multiqc_report.html')\n",")\n","\n","# Display the report within Jupyter\n","display(IFrame(src=os.path.join(report_path, 'mhcquant_multiqc_report.html'), width='100%', height=1000))"]}],"metadata":{"kernelspec":{"display_name":"peptide_analysis_test","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":2}
